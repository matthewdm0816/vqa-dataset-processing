{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import numpy as np\n",
    "import torch\n",
    "from icecream import ic\n",
    "from PIL import Image\n",
    "\n",
    "ic.configureOutput(outputFunction=print)\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from typing import Optional, Iterable, Union, List\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic| clip.available_models(): ['RN50', 'RN101', 'RN50x4', 'RN50x16', 'ViT-B/32', 'ViT-B/16']\n"
     ]
    }
   ],
   "source": [
    "ic(clip.available_models())\n",
    "device = torch.device(\"cuda:3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"RN50x16\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterchunk(iterator, chunksize: int):\n",
    "    from itertools import islice\n",
    "    passed = 0\n",
    "    while True:\n",
    "        chunk_iter = islice(iterator, passed, chunksize + passed)\n",
    "        try:\n",
    "            chunk_iter.__next__()\n",
    "        except StopIteration:\n",
    "            return\n",
    "        yield islice(iterator, passed, chunksize + passed)\n",
    "        passed += chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "\n",
    "class ImagePool:\n",
    "    @classmethod\n",
    "    def _getid(cls, image_path):\n",
    "        r\"\"\"\n",
    "        \"VizWiz-werwerwer-0001123.jpg\" => 1123\n",
    "        \"COCO_train2014_00000000123123.jpg\" => 123123\n",
    "        \"\"\"\n",
    "        filename = os.path.basename(image_path)\n",
    "        image_id = filename.split(\"_\")[-1]\n",
    "        image_id, _ = image_id.split(\".\")\n",
    "        return int(image_id)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: Union[str, List[str]],\n",
    "        preprocess,\n",
    "        init: bool = False,\n",
    "        limit: Optional[int] = None,\n",
    "        from_dataset: Optional[datasets.Dataset] = None,\n",
    "    ):\n",
    "        self.image_dict = dict()\n",
    "        self.image_feat_dict = dict()\n",
    "        self.image_grid_feat_dict = dict()\n",
    "        self.datasets = from_dataset\n",
    "        if isinstance(path, str):\n",
    "            self.path = [path]\n",
    "        else:\n",
    "            self.path = path\n",
    "        self.path = list(map(os.path.expanduser, self.path))\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "        if init:\n",
    "            self.init(limit=limit)\n",
    "\n",
    "    def init(self, num_workers: int = 32, limit: Optional[int] = None):\n",
    "        if num_workers < 1:\n",
    "            for filename in tqdm(glob.glob(self.path)):\n",
    "                image_id = self._getid(filename)\n",
    "                image = self.preprocess(Image.open(filename))\n",
    "                self.image_dict[image_id] = image\n",
    "        else:\n",
    "            from concurrent.futures import ThreadPoolExecutor, wait, ProcessPoolExecutor\n",
    "            from multiprocessing import Queue\n",
    "\n",
    "            # q = Queue()\n",
    "            executor = ThreadPoolExecutor(max_workers=num_workers)\n",
    "            futures = []\n",
    "            filelist = sorted(sum([glob.glob(path) for path in self.path], start=[]))\n",
    "            filelist = filelist[:limit] if limit is not None else filelist\n",
    "            total_files = len(filelist)\n",
    "            pbar = tqdm(total=total_files)\n",
    "\n",
    "            for filename in filelist:\n",
    "                future = executor.submit(self._load_single_image_mt, filename)\n",
    "                future.add_done_callback(lambda future: pbar.update(1))\n",
    "                futures.append(future)\n",
    "\n",
    "            wait(futures)  # it shall have been finished though\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, list):\n",
    "            return [self.image_feat_dict[key_item] for key_item in key]\n",
    "        else:\n",
    "            return self.image_feat_dict[key]\n",
    "\n",
    "    def _load_single_image_mt(self, filename):\n",
    "        iid = self._getid(filename)\n",
    "        image = self.preprocess(Image.open(filename))\n",
    "        self.image_dict[iid] = image\n",
    "\n",
    "    def encode(self, model, device):\n",
    "        logging.info(\"Beginning Encoding Images...\")\n",
    "        dataloader = DataLoader(list(self.image_dict.items()), batch_size=256)\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "                idxs, images = batch\n",
    "                encoded_images = model.encode_image(images.to(device))\n",
    "                for idx, encoded_image in zip(idxs, encoded_images):\n",
    "                    self.image_feat_dict[idx.item()] = encoded_image.cpu()\n",
    "\n",
    "    def encode_grid_feature(self, model, device):\n",
    "        logging.info(\"Beginning Encoding Images...\")\n",
    "        dataloader = DataLoader(\n",
    "            list(self.image_dict.items()), batch_size=512, num_workers=16\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "                idxs, images = batch\n",
    "                encoded_images, grid_feature = model.encode_image(\n",
    "                    images.to(device), return_fm=True\n",
    "                )\n",
    "                for idx, encoded_image in zip(idxs, encoded_images):\n",
    "                    self.image_feat_dict[idx.item()] = encoded_image.cpu()\n",
    "                    self.image_grid_feat_dict[idx.item()] = grid_feature.cpu()\n",
    "\n",
    "    def encode_idxs(self, model, device, idxs, chunksize: int = 32):\n",
    "        logging.info(\"Beginning Encoding Images...\")\n",
    "        with torch.no_grad():\n",
    "            for idxs_chunk in tqdm(\n",
    "                iterchunk(idxs, chunksize=chunksize), total=len(idxs) / chunksize\n",
    "            ):\n",
    "                idxs_chunk = list(idxs_chunk)\n",
    "                images = torch.stack(\n",
    "                    [self.image_dict[idx] for idx in idxs_chunk], dim=0\n",
    "                )\n",
    "                encoded_images, grid_features = model.encode_image(\n",
    "                    images.to(device), return_fm=True\n",
    "                )\n",
    "                grid_features = grid_features.transpose(1, 0)  # => N(HW+1)C\n",
    "                if self.datasets is None:\n",
    "                    self.datasets = datasets.Dataset.from_dict(\n",
    "                        {\n",
    "                            \"image_id\": idxs_chunk,\n",
    "                            \"feature\": encoded_images,\n",
    "                            \"grid_feature\": grid_features,\n",
    "                        }\n",
    "                    )\n",
    "                    self.datasets.save_to_disk(\"clip_features\")\n",
    "                    self.datasets = datasets.load_from_disk(\n",
    "                        \"clip_features\", keep_in_memory=False\n",
    "                    )\n",
    "                    ic(self.datasets, self.datasets.features)\n",
    "                else:\n",
    "                    newdataset = datasets.Dataset.from_dict(\n",
    "                        {\n",
    "                            \"image_id\": idxs_chunk,\n",
    "                            \"feature\": encoded_images,\n",
    "                            \"grid_feature\": grid_features,\n",
    "                        }\n",
    "                    )\n",
    "                    self.datasets = datasets.concatenate_datasets(\n",
    "                        [self.datasets, newdataset]\n",
    "                    )\n",
    "                for idx in idxs_chunk:\n",
    "                    del self.image_dict[idx]  # Clean up memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ac47d5a3184db1a0d8d49605678916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e177f5ac184815b7902142e06e73da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/318.1015625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic| self.datasets: Dataset({\n",
      "                       features: ['image_id', 'feature', 'grid_feature'],\n",
      "                       num_rows: 256\n",
      "                   })\n",
      "    self.datasets.features: {'feature': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None),\n",
      "                             'grid_feature': Sequence(feature=Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), length=-1, id=None),\n",
      "                             'image_id': Value(dtype='int64', id=None)}\n",
      "ic| image_pool.datasets: Dataset({\n",
      "                             features: ['image_id', 'feature', 'grid_feature'],\n",
      "                             num_rows: 81434\n",
      "                         })\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3d0374865f419fad87f0a9117357c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9421d5cda764a13bf7c3b36ffd3a9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/158.21875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic| image_pool.datasets: Dataset({\n",
      "                             features: ['image_id', 'feature', 'grid_feature'],\n",
      "                             num_rows: 121938\n",
      "                         })\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05eb7d3f4c245d6b0b28392bed186e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47034c9a9240432eac4c036f1bba7ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323.37109375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic| image_pool.datasets: Dataset({\n",
      "                             features: ['image_id', 'feature', 'grid_feature'],\n",
      "                             num_rows: 204721\n",
      "                         })\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "logging.info(\"Loading and Preprocessing Images and Loading Annotations...\")\n",
    "dataset=None\n",
    "for path in [\n",
    "    \"~/data/vqav2/img/test/test2015/*.jpg\",\n",
    "    \"~/data/vqav2/img/val/val2014/*.jpg\",\n",
    "    \"~/data/vqav2/img/train/train2014/*.jpg\",\n",
    "]:\n",
    "    image_pool = ImagePool(\n",
    "        path=path,\n",
    "        preprocess=preprocess,\n",
    "        init=True,\n",
    "        limit=None,\n",
    "        from_dataset=dataset\n",
    "    )\n",
    "    image_pool.encode_idxs(\n",
    "        model, device, list(image_pool.image_dict.keys()), chunksize=256\n",
    "    )\n",
    "    ic(image_pool.datasets)\n",
    "    dataset = image_pool.datasets\n",
    "    # dataset.save_to_disk('clip_features')\n",
    "    del image_pool\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload Dataset\n",
    "dataset.save_to_disk('clip_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_pool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cbbc18571898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Clean Ups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_feat_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimage_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_grid_feat_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_pool' is not defined"
     ]
    }
   ],
   "source": [
    "# Clean Ups\n",
    "image_pool.image_feat_dict = {}\n",
    "image_pool.image_grid_feat_dict = {}\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60aee0565937302cf0eb01f8c2c3ecd6548e281b6c48c0bb0e459ec70e5a7a30"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('k2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}